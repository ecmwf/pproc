#!/usr/bin/env python3

import argparse
import pickle
from itertools import chain, tee
from os import environ, makedirs, path

import eccodes
import numpy as np
import pandas as pd
from scipy.spatial import KDTree

pts_cache_dir = "PTS_CACHE_DIR"
pts_home_dir = "PTS_HOME_DIR"

parser = argparse.ArgumentParser()
parser.add_argument("--distance", help="Point search radius", default=300.0e3)
parser.add_argument("--number", help="Number range", default="1-50")
parser.add_argument("--super-sample", help="SS factor", default=10, type=int)
parser.add_argument("--grib-accuracy", help="GRIB bitsPerValue", default=8, type=int)
parser.add_argument("--grib-date", help="GRIB dataDate", default=None)
parser.add_argument("--grib-step", help="GRIB stepRange", default=None)

parser.add_argument(
    "--grib-template",
    help="GRIB template (env. variable '" + pts_home_dir + "')",
    default="O640.grib1",
)

parser.add_argument(
    "--caching",
    help="Caching (env. variable '" + pts_cache_dir + "')",
    action="store_true",
)

parser.add_argument("fin", help="Input points file", metavar="in")
parser.add_argument("fout", help="Output GRIB file", metavar="out")

args = parser.parse_args()
print(args)


def previous_and_current(some_iterable):
    prevs, currs = tee(some_iterable, 2)
    prevs = chain([None], prevs)
    return zip(prevs, currs)


def ll_to_ecef(lat, lon, height=0.0, radius=6371229.0):
    lonr = np.radians(lon)
    latr = np.radians(lat)

    x = (radius + height) * np.cos(latr) * np.cos(lonr)
    y = (radius + height) * np.cos(latr) * np.sin(lonr)
    z = (radius + height) * np.sin(latr)
    return x, y, z


def parse_range(rstr):
    s = set()
    for part in rstr.split(","):
        x = part.split("-")
        s.update(range(int(x[0]), int(x[-1]) + 1))
    return sorted(s)


numbers = parse_range(args.number)

if pts_home_dir in environ:
    tpl_dir = environ[pts_home_dir]
else:
    tpl_dir = path.dirname(__file__)
tpl_path = path.realpath(path.join(tpl_dir, args.grib_template))
print("Loading template: '{}'".format(tpl_path))


with open(tpl_path, "rb") as f:
    h = eccodes.codes_grib_new_from_file(f)
    assert h is not None

    N = eccodes.codes_get(h, "numberOfDataPoints")

    # k-d tree
    tree_path = eccodes.codes_get(h, "md5GridSection") + ".tree"
    if pts_cache_dir in environ:
        tree_path = path.join(environ[pts_cache_dir], tree_path)

    if args.caching and path.exists(tree_path):
        print("Loading cache file: '{}'".format(tree_path))
        with open(tree_path, "rb") as f:
            tree = pickle.load(f)
    else:
        it = eccodes.codes_grib_iterator_new(h, 0)

        P = np.empty([N, 3])
        i = 0
        while True:
            result = eccodes.codes_grib_iterator_next(it)
            if not result:
                break
            [lat, lon, value] = result

            assert i < N
            P[i, :] = ll_to_ecef(lat, lon)

            i += 1

        eccodes.codes_grib_iterator_delete(it)
        tree = KDTree(P)

    if args.caching and not path.exists(tree_path):
        tpl_dir = path.dirname(tree_path)
        if tpl_dir:
            makedirs(tpl_dir, mode=888, exist_ok=True)
            assert path.isdir(tpl_dir)
        with open(tree_path, "wb") as f:
            pickle.dump(tree, f)
        print("Created cache file: '{}'".format(tree_path))

    # input
    df = pd.read_csv(
        args.fin,
        sep=r"\s+",
        header=None,
        names=["lat", "lon", "number", "date", "step", "wind", "msl"],
        usecols=["lat", "lon", "number", "date", "step"],
    )

    df["x"], df["y"], df["z"] = ll_to_ecef(df["lat"], df["lon"])
    df["t"] = df["step"] + 2400 * (df["date"] - df["date"].min())
    df.drop(["lat", "lon", "date", "step"], axis=1, inplace=True)

    dfi = pd.DataFrame()
    for n in numbers:
        track = df[df.number == n].sort_values("t")
        if len(track.index) < 2:
            continue

        ti = np.array([])
        for a, b in previous_and_current(track.t):
            if a is not None:
                ti = np.append(
                    ti,
                    np.linspace(a, b, num=args.super_sample, endpoint=False)
                    if args.super_sample > 1
                    else a,
                )
        ti = np.append(ti, [track.t[track.index[-1]]])

        dfi = dfi.append(
            pd.DataFrame(
                {
                    "number": np.full(len(ti), n),
                    "t": ti,
                    "x": np.interp(ti, track.t, track.x),
                    "y": np.interp(ti, track.t, track.y),
                    "z": np.interp(ti, track.t, track.z),
                }
            )
        )
    df = dfi

    # probability field
    val = np.zeros(N)
    for n in numbers:
        track = df[df.number == n]
        pts = set()
        for row in track.itertuples():
            p = (row.x, row.y, row.z)
            pts.update(tree.query_ball_point(p, r=args.distance))
        for i in pts:
            assert i < N
            val[i] = val[i] + 1.0

    val = np.minimum(val / len(numbers), 1.0) * 100.0  # %

    # write results
    if args.grib_accuracy:
        eccodes.codes_set(h, "bitsPerValue", args.grib_accuracy)
    if args.grib_date:
        eccodes.codes_set(h, "dataDate", args.grib_date)
    if args.grib_step:
        eccodes.codes_set(h, "stepRange", args.grib_step)

    eccodes.codes_set_values(h, val)

    with open(args.fout, "wb") as f:
        eccodes.codes_write(h, f)

    eccodes.codes_release(h)
